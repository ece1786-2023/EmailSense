Subject:
New course with WhyLabs: Quality and Safety for LLM Applications
Content:
Dear Isabella, 
It's always vital to address safety and quality in the applications that you build. Applications built on LLMs pose special challenges.
 
Introducing Quality and Safety for LLM Applications, a new short course built in collaboration with WhyLabs, designed to help you make your LLM applications safer and more user-friendly. 
 
Upon completing this course, youâ€™ll be able to:
Identify hallucinations with methods like SelfCheckGPT 
Detect jailbreaks (prompts that attempt to manipulate LLM responses) using sentiment analysis and implicit toxicity detection models.
Identify data leakage using entity recognition and vector similarity analysis.
Build your own monitoring system to evaluate app safety and security over time.
Start making your LLM-based apps better, safer, and more secure!
